{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **ðŸ“š Text Preprocessing Master File for NLP / ML / GenAI**"
      ],
      "metadata": {
        "id": "l3K0uAsbbKlc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NByBN9iFbJ3y"
      },
      "outputs": [],
      "source": [
        "# âœ… 1. Import Required Libraries\n",
        "import re\n",
        "import emoji\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# âœ… 2. Download Required NLTK Resources (Only run once)\n",
        "# These resources include stopword lists, tokenizers, and lemmatization dictionaries.\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# âœ… 3. Define Individual Cleaning Functions\n",
        "# Each function handles a specific part of the text cleaning pipeline.\n",
        "\n",
        "# ðŸ”¹ Convert all characters to lowercase for uniformity\n",
        "def to_lower(text):\n",
        "    return text.lower()\n",
        "\n",
        "# ðŸ”¹ Remove emojis from text to avoid noise in analysis\n",
        "def remove_emojis(text):\n",
        "    emoji_pattern = re.compile(\"[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F1E0-\\U0001F1FF]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "# ðŸ”¹ Optional: Convert emojis to their textual description (e.g., ðŸ˜ƒ â†’ :grinning_face:)\n",
        "def demojize_emojis(text):\n",
        "    return emoji.demojize(text)\n",
        "\n",
        "# ðŸ”¹ Remove HTML tags (e.g., <br>, <p>, etc.)\n",
        "def remove_html_tags(text):\n",
        "    return BeautifulSoup(text, \"html.parser\").get_text()\n",
        "\n",
        "# ðŸ”¹ Remove URLs (e.g., http://example.com)\n",
        "def remove_urls(text):\n",
        "    return re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
        "\n",
        "# ðŸ”¹ Remove punctuation and special characters\n",
        "# Keeps only alphanumeric characters and whitespace\n",
        "def remove_punctuation(text):\n",
        "    return re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "# ðŸ”¹ Tokenize text (split into individual words)\n",
        "def tokenize_text(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "# ðŸ”¹ Remove common stopwords like \"the\", \"is\", \"and\"\n",
        "def remove_stopwords(tokens):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    return [word for word in tokens if word not in stop_words]\n",
        "\n",
        "# ðŸ”¹ Lemmatize words (e.g., \"running\" â†’ \"run\") for root-word consistency\n",
        "# This improves model generalization\n",
        "def lemmatize_tokens(tokens):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "# âœ… 4. Create a Full Cleaning Pipeline\n",
        "# This function applies all steps in sequence to fully prepare text for NLP tasks\n",
        "# For example: turning a noisy movie review with emojis, stopwords, and punctuation into clean, model-ready tokens.\n",
        "\n",
        "def full_clean(text):\n",
        "    text = to_lower(text)                      # Step 1: Lowercase\n",
        "    text = remove_html_tags(text)             # Step 2: Remove HTML tags\n",
        "    text = remove_urls(text)                  # Step 3: Remove URLs\n",
        "    text = remove_emojis(text)                # Step 4: Remove emojis\n",
        "    text = remove_punctuation(text)           # Step 5: Remove punctuation\n",
        "    tokens = tokenize_text(text)              # Step 6: Tokenize words\n",
        "    tokens = remove_stopwords(tokens)         # Step 7: Remove stopwords\n",
        "    tokens = lemmatize_tokens(tokens)         # Step 8: Lemmatize words\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# âœ… 5. Example Test Case\n",
        "# This demonstrates how to use the pipeline on a sample text string.\n",
        "# ðŸ§ª You can replace this text with any raw input like reviews, tweets, or chat logs.\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    original_text = \"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />Visit http://example.com to read more! OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\"\n",
        "    print(\"Original Text:\\n\", original_text)\n",
        "    print(\"\\nCleaned Text:\\n\", full_clean(original_text))\n"
      ]
    }
  ]
}