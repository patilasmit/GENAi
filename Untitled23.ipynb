{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4603108-25c3-48df-8e08-959a056a37e6",
   "metadata": {},
   "source": [
    "## ðŸš€ Hi Everyone, Welcome to the GenAI Journey! ðŸ¤–âœ¨\n",
    "#### ðŸŒŸ As this is our very first practical in this series, weâ€™ll start with the most important step: \n",
    "#### ðŸ“Œ **Data Cleaning (also called Text Preprocessing for NLP / ML / GenAI)** \n",
    "##### This process transforms messy, real-world text into clean, structured input that models can understand and learn from.\n",
    "##### This file contains reusable and modular functions for cleaning raw text.\n",
    "##### It's designed for use in NLP tasks, chatbots, sentiment analysis, and LLM-based systems.\n",
    "##### Each step in this script is explained with clear comments and practical use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27322cd-c6cd-472d-a65d-6ecd846344eb",
   "metadata": {},
   "source": [
    "### âœ… 1. Import Required Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0afc7d0d-d2c7-4ad2-8aa0-c71a1a237060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8437a6a4-35a6-4df8-91a1-f09da9d82e66",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/Ankit152/IMDB-sentiment-analysis/master/IMDB-Dataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data =pd.read_csv(r\"https://raw.githubusercontent.com/Ankit152/IMDB-sentiment-analysis/master/IMDB-Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de4daf3c-878c-4784-aeb3-ef0b3cd673d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42e33a1a-5a73-48f9-85d4-8d5bff649c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8437f7c6-b0a3-47b8-9566-b71f22aebd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee6d4e-59c3-4f5f-bf15-81380a8cfd18",
   "metadata": {},
   "source": [
    "#### As we see that our user reviews data (like movie feedback) is not clean so we will clean by removing noise, lowercasing the text, lemmatizing, and removing stopwords to prepare the text for NLP models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7ae619-2c20-4d8b-bfbf-1025fb1992dd",
   "metadata": {},
   "source": [
    "### âœ… 2. Define Individual Cleaning Functions (Text Pre-Processing)\n",
    "##### Each function handles a specific part of the text cleaning pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdcf295-6ef8-4bfe-bca2-29c151396822",
   "metadata": {},
   "source": [
    "#### 1. Lowercasing \n",
    "##### ðŸ”¹ Convert all characters to lowercase for uniformity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "25c235a1-2683-48f5-acb9-85205bb42754",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "88381c8a-f4c9-4aae-8eae-0a777863e497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one of the other reviewers has mentioned that ...\n",
       "1        a wonderful little production. the filming tec...\n",
       "2        i thought this was a wonderful way to spend ti...\n",
       "3        basically there's a family where a little boy ...\n",
       "4        petter mattei's \"love in the time of money\" is...\n",
       "                               ...                        \n",
       "49995    i thought this movie did a down right good job...\n",
       "49996    bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    i am a catholic taught in parochial elementary...\n",
       "49998    i'm going to have to disagree with the previou...\n",
       "49999    no one expects the star trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed8fbb2-0f27-429e-a9fd-65bd37808ad2",
   "metadata": {},
   "source": [
    "#### 2. Remove HTMLs Tags \n",
    "##### ðŸ”¹Remove HTML tags from text to ensures data is fully readable and clean for NLP or GenAI models  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f974ac8f-b7d9-42f1-a6c6-06179615d57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2dec65a7-ad6e-436b-81c1-5eeb5827153c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "118fa95f-d748-4069-9ab7-a30231b69b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To find pattern from data we use Regular Expression (Text Data)\n",
    "import re\n",
    "def Remove_html_tags(text):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(\"\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9bc41067-b993-4cc1-a82b-86b3450170d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Remove_html_tags(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3d44f82c-52dd-42fb-a991-133f5d0f522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(Remove_html_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616e7d21-d44b-4070-9984-4a5b55300538",
   "metadata": {},
   "source": [
    "#### 3. Remove Urls\n",
    "##### ðŸ”¹Remove URLs from Text(e.g., http://example.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4c82cc50-cd4e-4261-973d-72e48d917bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(\"\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a0874aa1-70d7-44d6-a858-84a26b5c781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'Visit on Website https://www.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "062aeef9-675e-4ef3-9c78-d554c61f1cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Visit on Website '"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Remove_url(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4fa4eaf5-63b7-4d09-915d-9b8e7e6a53e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(Remove_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea35ff7-c353-4ba3-afda-d7dc6959b102",
   "metadata": {},
   "source": [
    "#### 4. Remove punctuation and special characters\n",
    "##### ðŸ”¹ Attribute Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0151ecdb-4821-4081-84fc-449bad976bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9a7aea69-1cfb-4d88-9b48-2df42eba0ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cb11bdcd-db3f-417f-ba86-32d2b6f3474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e80e91b0-23c5-4163-a7de-56d2354986ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Remove_punct(text):\n",
    "    for char in exclude:\n",
    "        text = text.replace(char,\"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e94db812-4e72-4ef2-b701-098ab2fe0fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Basically theres a family where a little boy Jake thinks theres a zombie in his closet  his parents are fighting all the timebr br This movie is slower than a soap opera and suddenly Jake decides to become Rambo and kill the zombiebr br OK first of all when youre going to make a film you must Decide if its a thriller or a drama As a drama the movie is watchable Parents are divorcing  arguing like in real life And then we have Jake with his closet which totally ruins all the film I expected to see a BOOGEYMAN similar movie and instead i watched a drama with some meaningless thriller spotsbr br 3 out of 10 just for the well playing parents  descent dialogs As for the shots with Jake just ignore them'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Remove_punct(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f70105ea-c870-4b05-848d-27f4c6857673",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(Remove_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1ca847e1-2b8e-4e90-abf3-bac56e2cafd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i thought this was a wonderful way to spend time on a too hot summer weekend sitting in the air conditioned theater and watching a lighthearted comedy the plot is simplistic but the dialogue is witty and the characters are likable even the well bread suspected serial killer while some may be disappointed when they realize this is not match point 2 risk addiction i thought it was proof that woody allen is still fully in control of the style many of us have grown to lovethis was the most id laughed at one of woodys comedies in years dare i say a decade while ive never been impressed with scarlet johanson in this she managed to tone down her sexy image and jumped right into a average but spirited young womanthis may not be the crown jewel of his career but it was wittier than devil wears prada and more interesting than superman a great comedy to go see with friends'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b902bf87-8182-46b4-b13d-0802512d6475",
   "metadata": {},
   "source": [
    "#### 5. Slangs (Short Words / Abbrivation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e37ac9d6-e190-4666-b9e5-c8f950bbafe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_word= {\"AFK\": \"Away From Keyboard\",\n",
    "\"ASAP\":\"As Soon As Possible\",\n",
    "\"BTW\":\"By The Way\",\n",
    "\"B4\":\"Before\",\n",
    "\"LAMO\":\"Laugh My A.. Off\",\n",
    "\"FYI\":\"For your information\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "44ebb561-3a30-419b-a997-66b6ec330ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"FYI this is not true\"\n",
    "text2=\"LAMO the class was so funny\"\n",
    "text3=\"i want report ASAP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "01501424-3a4b-4bf1-85bd-b4d42baf7bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_conversion(text):\n",
    "  new_text=[]\n",
    "  for w in text.split():\n",
    "      if w.upper() in chat_word:\n",
    "        new_text.append(chat_word[w.upper()])\n",
    "      else:\n",
    "        new_text.append(w)\n",
    "  return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4d4e6b07-6d5b-4aa6-81f5-91a33b4377aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For your information this is not true'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversion(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37471ec0-64db-45ec-80fb-69a8610d4aa5",
   "metadata": {},
   "source": [
    "#### 6. spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "38ead512-8c97-4405-8ac9-694cfd1cd0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob #importing spelling correct module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "78881150-b312-45b0-a4e9-1d0a0e927408",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'plese downlod my notbook' # Writing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "40d95333-5af4-4d93-a1ce-11732380ad79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"plese downlod my notbook\")"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4adf806a-ebb1-4b63-9b66-2e9f92992b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "txtblob = TextBlob(text) #creating  a callable variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4ac72a2b-77c7-4004-89a5-402cd5f45cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'please download my notebook'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txtblob.correct().string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e3b681-8917-46ba-83ee-0de3167efe27",
   "metadata": {},
   "source": [
    "#### 7. Remove common stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9287ea8c-2915-4839-b55d-1f83095cecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2f27c1b0-5eee-47e7-829a-b56f195fc4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\asmit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8c2d1c75-3fbf-461b-a5fb-77c9966ebcd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b1fa55ad-b714-41ce-b06e-b20a11b6950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text5 = \"I'am Asmit and we all are learning GenAi and Nlp which is Important\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c6dbfcdd-24b8-46d9-bb04-e99344c6660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    new_text=[]\n",
    "    for word in text.split():\n",
    "        if word in stopwords.words(\"english\"):\n",
    "         new_text.append(\"\")\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "06893322-314e-445d-ad7e-d37ba2852668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'am Asmit     learning GenAi  Nlp   Important\""
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(text5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e539cd-c2db-469c-90be-e46ae7182675",
   "metadata": {},
   "source": [
    "#### 8. Remove emojis from text to avoid noise in analysis & Convert emojis to their textual description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "18acae44-e360-4a2c-bb67-930514445a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "797f930a-9fc8-4656-9127-b87fa1bfa1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text = \"This is a ðŸ˜ƒ sample text with some stopwords like a and the ðŸš€\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "98fbdcf3-6b96-4850-9bfc-e7c736b85a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\"[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F1E0-\\U0001F1FF]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "9e529b25-b5c2-4571-8585-0bda804e1c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a  sample text with some stopwords like a and the '"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emojis(original_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fe473c-39d2-44d6-8bc9-6dd67f63010a",
   "metadata": {},
   "source": [
    "##### Convert emojis to their textual description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "fc72371a-bd6b-4349-a573-bf8097dc9362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demojize_emojis(text):\n",
    "    return emoji.demojize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "34f53265-97fe-4a40-8c1e-99daefd57c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a :grinning_face_with_big_eyes: sample text with some stopwords like a and the :rocket:'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demojize_emojis(original_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b7f5d0-1d89-4e64-82ff-abe2042b1dfe",
   "metadata": {},
   "source": [
    "#### 9. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f1c9b07b-f5b8-4c56-9eeb-c64e7559643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "bf774273-8b2f-4683-add8-30b39f2097db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\asmit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "332c967a-2afb-4d8a-aa1d-a1d8dccbd2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_text = \"i am going to delhi evening\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "ea91dda1-3271-45a4-a6be-d1a11abf4aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'going', 'to', 'delhi', 'evening']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(my_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a71fdb3-b362-4129-82c4-1cba6718a933",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_corpus = \"\"\"Generative artificial intelligence (generative AI, genAI, GenAI, GAI or GenAI[1]) is artificial intelligence capable of generating text, images or other data using generative models,[2] often in response to prompts.[3][4] Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics.[5][6]\n",
    "Improvements in transformer-based deep neural networks enabled an AI boom of generative AI systems in the early 2020s. These include large language model (LLM) chatbots such as ChatGPT, Copilot, Bard, and LLaMA, and text-to-image artificial intelligence art systems such as Stable Diffusion, Midjourney, and DALL-E.[7][8][9] Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88213bd8-2e31-4c9a-bf39-9eb5f52ab7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generative artificial intelligence (generative AI, genAI, GenAI, GAI or GenAI[1]) is artificial intelligence capable of generating text, images or other data using generative models,[2] often in response to prompts.[3][4] Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics.[5][6]\\nImprovements in transformer-based deep neural networks enabled an AI boom of generative AI systems in the early 2020s. These include large language model (LLM) chatbots such as ChatGPT, Copilot, Bard, and LLaMA, and text-to-image artificial intelligence art systems such as Stable Diffusion, Midjourney, and DALL-E.[7][8][9] Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "168ee749-b14c-4bcf-b53d-38bc296c59e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Generative artificial intelligence (generative AI, genAI, GenAI, GAI or GenAI[1]) is artificial intelligence capable of generating text, images or other data using generative models,[2] often in response to prompts.',\n",
       " '[3][4] Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics.',\n",
       " '[5][6]\\nImprovements in transformer-based deep neural networks enabled an AI boom of generative AI systems in the early 2020s.',\n",
       " 'These include large language model (LLM) chatbots such as ChatGPT, Copilot, Bard, and LLaMA, and text-to-image artificial intelligence art systems such as Stable Diffusion, Midjourney, and DALL-E.[7][8][9] Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.']"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(my_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c4f2c5-b001-4ccd-97f2-6839a094e51e",
   "metadata": {},
   "source": [
    "#### we can do it by using nltk and even with spacy\n",
    "\n",
    "##### split\n",
    "##### regular expression(simple google)\n",
    "##### nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5559c6a2-9d4c-4f6b-932a-71e6e761f4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English NLP model from spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f51c39f7-d179-49ca-9fed-b9e78c94451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    # Process the text with the spacy model\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Extract tokens from the processed document\n",
    "    tokens = [token.text for token in doc]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c3f553c-fe75-4086-9822-fa93dd90a950",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=tokenize_text(my_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81299fb8-d743-419e-8d30-f4c02898873b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative\n",
      "artificial\n",
      "intelligence\n",
      "(\n",
      "generative\n",
      "AI\n",
      ",\n",
      "genAI\n",
      ",\n",
      "GenAI\n",
      ",\n",
      "GAI\n",
      "or\n",
      "GenAI[1\n",
      "]\n",
      ")\n",
      "is\n",
      "artificial\n",
      "intelligence\n",
      "capable\n",
      "of\n",
      "generating\n",
      "text\n",
      ",\n",
      "images\n",
      "or\n",
      "other\n",
      "data\n",
      "using\n",
      "generative\n",
      "models,[2\n",
      "]\n",
      "often\n",
      "in\n",
      "response\n",
      "to\n",
      "prompts.[3][4\n",
      "]\n",
      "Generative\n",
      "AI\n",
      "models\n",
      "learn\n",
      "the\n",
      "patterns\n",
      "and\n",
      "structure\n",
      "of\n",
      "their\n",
      "input\n",
      "training\n",
      "data\n",
      "and\n",
      "then\n",
      "generate\n",
      "new\n",
      "data\n",
      "that\n",
      "has\n",
      "similar\n",
      "characteristics.[5][6\n",
      "]\n",
      "\n",
      "\n",
      "Improvements\n",
      "in\n",
      "transformer\n",
      "-\n",
      "based\n",
      "deep\n",
      "neural\n",
      "networks\n",
      "enabled\n",
      "an\n",
      "AI\n",
      "boom\n",
      "of\n",
      "generative\n",
      "AI\n",
      "systems\n",
      "in\n",
      "the\n",
      "early\n",
      "2020s\n",
      ".\n",
      "These\n",
      "include\n",
      "large\n",
      "language\n",
      "model\n",
      "(\n",
      "LLM\n",
      ")\n",
      "chatbots\n",
      "such\n",
      "as\n",
      "ChatGPT\n",
      ",\n",
      "Copilot\n",
      ",\n",
      "Bard\n",
      ",\n",
      "and\n",
      "LLaMA\n",
      ",\n",
      "and\n",
      "text\n",
      "-\n",
      "to\n",
      "-\n",
      "image\n",
      "artificial\n",
      "intelligence\n",
      "art\n",
      "systems\n",
      "such\n",
      "as\n",
      "Stable\n",
      "Diffusion\n",
      ",\n",
      "Midjourney\n",
      ",\n",
      "and\n",
      "DALL\n",
      "-\n",
      "E.[7][8][9\n",
      "]\n",
      "Companies\n",
      "such\n",
      "as\n",
      "OpenAI\n",
      ",\n",
      "Anthropic\n",
      ",\n",
      "Microsoft\n",
      ",\n",
      "Google\n",
      ",\n",
      "and\n",
      "Baidu\n",
      "as\n",
      "well\n",
      "as\n",
      "numerous\n",
      "smaller\n",
      "firms\n",
      "have\n",
      "developed\n",
      "generative\n",
      "AI\n",
      "models\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for word in tokens:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da0114f-5fed-429a-b686-b742143daea2",
   "metadata": {},
   "source": [
    "#### 10. Stemming and Lemmetization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
